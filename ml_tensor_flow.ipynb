{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/14 18:37:57 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.17.0, but the installed version is 2.18.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Model, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import os\n",
    "import uuid\n",
    "import requests\n",
    "import json\n",
    "# Enable automatic logging\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Dummy Data (Time Series)\n",
    "# Let's create some sequential data for demonstration.\n",
    "timesteps = 50   # Number of timesteps for each sample\n",
    "features = 1     # Number of features\n",
    "samples = 1000   # Total samples\n",
    "\n",
    "# Generate sequential data with some noise\n",
    "x_train = np.random.rand(samples, timesteps, features)\n",
    "y_train = np.random.rand(samples, 1)  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the LSTM Model\n",
    "model = Sequential([\n",
    "    Input(shape=(timesteps, features)),  # Specify the input shape here\n",
    "    LSTM(64),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1652  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1518 - val_loss: 0.0924\n",
      "Epoch 2/5\n",
      "\u001b[1m17/25\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0945 - val_loss: 0.0859\n",
      "Epoch 3/5\n",
      "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0882 - val_loss: 0.0853\n",
      "Epoch 4/5\n",
      "\u001b[1m18/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0889 - val_loss: 0.0848\n",
      "Epoch 5/5\n",
      "\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0921 - val_loss: 0.0845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Run ID: 9f05cb074437427a821f23c11b597844\n"
     ]
    }
   ],
   "source": [
    "# 3. Start an MLflow Run to Log the Model\n",
    "with mlflow.start_run() as run:\n",
    "    # Train the model (logged automatically by mlflow.tensorflow.autolog())\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # MLflow automatically logs model parameters, metrics, and artifacts\n",
    "    # including the model, so no need for explicit log_model calls here.\n",
    "\n",
    "    # Print the run ID for reference (useful for tracking experiments in MLflow UI)\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define Paths and Download the Model\n",
    "# Define paths for saving model artifacts locally\n",
    "local_model_path = \"./downloaded_model\"\n",
    "model_uri = f\"runs:/{run_id}/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andressaldana/anaconda3/envs/cloud_eng_2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 12/12 [00:00<00:00, 3528.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to ./downloaded_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the model artifacts\n",
    "mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=local_model_path)\n",
    "print(f\"Model downloaded to {local_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure ML client\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"e55be53a-84c8-425d-8430-8151a50b6e6d\",\n",
    "    resource_group_name=\"TCAML\",\n",
    "    workspace_name=\"tcaml-workspace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading model (0.23 MBs): 100%|██████████| 228316/228316 [00:00<00:00, 335182.71it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered with name: LSTMModel_andres and version: 1\n"
     ]
    }
   ],
   "source": [
    "# 6. Register the Model in Azure ML\n",
    "model_name = \"LSTMModel_andres\"\n",
    "model_description = \"LSTM model for time series prediction, registered from local MLflow artifacts.\"\n",
    "\n",
    "# Register the model using the downloaded artifacts\n",
    "model = Model(\n",
    "    path=os.path.join(local_model_path, \"model\"),  # Path to the downloaded model directory\n",
    "    type=AssetTypes.MLFLOW_MODEL,                  # Specify the model type as MLflow model\n",
    "    name=model_name,\n",
    "    description=model_description,\n",
    ")\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "print(f\"Model registered with name: {registered_model.name} and version: {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create and Deploy an Online Endpoint\n",
    "# Create a unique name for the endpoint\n",
    "online_endpoint_name = \"lstm-endpoint-\" + str(uuid.uuid4())[:8]\n",
    "\n",
    "# define an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"random_numbers\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.mlflow could not be imported. Please ensure that latest 'azureml-mlflow' has been installed in the current python environment\n",
      "Endpoint \"lstm-endpoint-cceabdba\" with provisioning state \"Succeeded\" is retrieved\n"
     ]
    }
   ],
   "source": [
    "# create the online endpoint (2 minutes)\n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "print(f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instance type Standard_DS2_v2 may be too small for compute resources. Minimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: https://learn.microsoft.com/en-us/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\n",
      "Check: endpoint lstm-endpoint-cceabdba exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.mlflow could not be imported. Please ensure that latest 'azureml-mlflow' has been installed in the current python environment\n",
      ".........................................................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'lstm-endpoint-cceabdba', 'type': 'Managed', 'name': 'lstm-deployment-andres', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/e55be53a-84c8-425d-8430-8151a50b6e6d/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/odidp:6133be2e-2f4f-442b-a4c9-869d74222503:03cb06a0-1887-4109-81d5-fda79e500f08?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/e55be53a-84c8-425d-8430-8151a50b6e6d/resourceGroups/TCAML/providers/Microsoft.MachineLearningServices/workspaces/tcaml-workspace/onlineEndpoints/lstm-endpoint-cceabdba/deployments/lstm-deployment-andres', 'Resource__source_path': '', 'base_path': '/Users/andressaldana/Desktop/Reto', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x1691967d0>, 'serialize': <msrest.serialization.Serializer object at 0x169232020>, 'model': '/subscriptions/e55be53a-84c8-425d-8430-8151a50b6e6d/resourceGroups/TCAML/providers/Microsoft.MachineLearningServices/workspaces/tcaml-workspace/models/LSTMModel_andres/versions/1', 'code_configuration': None, 'environment': '/subscriptions/e55be53a-84c8-425d-8430-8151a50b6e6d/resourceGroups/TCAML/providers/Microsoft.MachineLearningServices/workspaces/tcaml-workspace/environments/DefaultNcdEnv-mlflow-ubuntu20-04-py38-cpu-inference/versions/20241003v2', 'environment_variables': {'MLFLOW_MODEL_FOLDER': 'model', 'AZUREML_EXTRA_CONDA_YAML_ABS_PATH': '/var/azureml-app/azureml-models/LSTMModel_andres/1/model/conda.yaml', 'AML_APP_INSIGHTS_KEY': '58f1abb3-221f-4132-8e4e-6638e595ada4', 'AML_APP_INSIGHTS_ENDPOINT': 'https://dc.services.visualstudio.com/v2/track', 'AML_APP_INSIGHTS_ENABLED': 'true', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/LSTMModel_andres/1'}, 'app_insights_enabled': True, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x169232ec0>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x1692338b0>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x169232290>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x169233fa0>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_DS2_v2', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Define and create a deployment for the model\n",
    "deployment_name = \"lstm-deployment-andres\"\n",
    "# Gretting the registered model from Azure\n",
    "registered_model_name = model_name\n",
    "latest_model_version = max([int(m.version) for m in ml_client.models.list(name=registered_model_name)])\n",
    "model_deploy = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model_deploy,\n",
    "    instance_type=\"Standard_DS2_v2\",  # Specify the instance type for deployment # Standard_DS3_v2\n",
    "    instance_count=1,                 # Number of instances for the deployment\n",
    "    app_insights_enabled=True  # Enable Application Insights for logging\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:msrest.serialization:Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
      "WARNING:msrest.serialization:Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.mlflow could not be imported. Please ensure that latest 'azureml-mlflow' has been installed in the current python environment\n",
      "Deployment 'lstm-deployment-andres' is live at endpoint 'lstm-endpoint-cceabdba'.\n"
     ]
    }
   ],
   "source": [
    "# Route 100% of traffic to the deployment\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f\"Deployment '{deployment_name}' is live at endpoint '{online_endpoint_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.228822723031044]]\n"
     ]
    }
   ],
   "source": [
    "# 9. Test the Endpoint (Optional)\n",
    "# Get the endpoint's scoring URI and API key\n",
    "endpoint = ml_client.online_endpoints.get(online_endpoint_name)\n",
    "scoring_uri = endpoint.scoring_uri\n",
    "api_key = ml_client.online_endpoints.get_keys(online_endpoint_name).primary_key\n",
    "\n",
    "# Original input data: list of sequences, each with 50 timesteps\n",
    "input_data = [[0.1] * 50]  # Example with one sequence\n",
    "input_array = np.array(input_data) # Reshape to add the feature dimension\n",
    "input_array = input_array.reshape((input_array.shape[0], input_array.shape[1], 1)) # New shape: (number of sequences, timesteps, features)\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n",
    "data = json.dumps({\"input_data\": input_array.tolist()})  # Adjust based on your LSTM input format\n",
    "\n",
    "# Send a test request\n",
    "response = requests.post(scoring_uri, headers=headers, data=data)\n",
    "print(\"Prediction:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud_eng_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
